---
layout: page
title: Research Statement
---

## What type of research do we do?

<ul class="hlp-orbit" data-orbit>
  <li>
    <img src="{{site.baseurl}}/pics/florian_katrina_yucatan.jpg" alt="Yucatec fieldworkd" />
    <div class="orbit-caption">
      T. Florian Jaeger and Katrina Housel Furth in the Yucatec doing fieldwork on Mayan in 2009
    </div>
  </li>
  <li class="active">
    <img src="{{site.baseurl}}/pics/testpattern_16x9.png" alt="A TV test pattern" />
    <div class="orbit-caption">
      People really need to give me some pictures
    </div>
  </li>
  <li>
    <img src="{{site.baseurl}}/pics/neuron_16x9.jpg" alt="A random neuron pic" />
    <div class="orbit-caption">
      Seriously guys, I'm just picking some random crap from Google Image Search
    </div>
  </li>
</ul>

**HLP lab research** focuses on language production and comprehension and the interaction between them. We use mathematical frameworks to develop computational models of how the systems underlying language processing and production facilitate robust communication and test them against behavioral data from speech, phonological, morphological, syntactic and discourse processing. This involves, to an increasing extent, research in **implicit distributional/statistical learning, adaptation to the statistics of the environments and how we adjust our processing and productions based on recent experience and feedback**. While most of our research focuses on online processing, we are also interested in how these mechanisms shape language over time, explaining historical language change and typological patterns through biases operating during language acquisition or throughout life.

**In production**, we investigate how speakers plan their utterances and to what extent decision during incremental language production are guided by general computational principles (such as the uniform distribution of information over time or over planning units to minimize comprehension effort and to maximize information transfer; or efficient use of limited resources such as syntactic working memory). We investigate these decisions at many levels of linguistic representation, including phonological, morphological, and grammatical encoding; decision about speech rate at the lowest level of production; decisions about referential expressions (pronominalization; ellipsis); and decisions as to how to structure a discourse at higher levels of production.

**In comprehension**, we are interested in similar computational principles. Building on work over the last decades that has shown that comprehenders almost instantaneously integrate evidence from multiple information sources, we investigate to what extent parsing makes optimal use of available information. How is top-down and bottom-up evidence integrated in comprehension? Are all source of information weighted according to how reliable and available they are or are there differences in the influence and time course between different information sources that are incompatible with the strongest version of ideal observer models of comprehension. When we observe such deviations from optimality where and when do they occur?

We employ a variety of computational and behavioral paradigms (e.g., eye-tracking, reading studies, speech perception experiments, production experiments, implicit learning paradigms, interactive communication paradigms, artificial language learning, iterated artificial language learning, corpus studies on conversational speech, computational simulations, statistical modeling). We conduct studies in the lab, abroad (e.g., in Mexico), and over the web via CrowdSourcing. Our research tends to include cross-linguistic components (e.g., Japanese, Yucatec Maya, Chinese and larger-scale cross-linguistic comparisons) and is interdisciplinary - we present at linguistics, psycholinguistic, cognitive science, and computer science conferences.

## Learn more

You can listen to and watch the following talk summarizing some of our work on efficiency in language production (given in April 2010 at Rutgers. Thanks to Chris Kourtev and Andrew Watts for preparing the video).

<div class="flex-video">
  <iframe width="420" height="315" src="https://www.youtube.com/embed/1fFkO7xV0SY" frameborder="0" allowfullscreen></iframe>
</div>

A list of [ongoing projects](http://wiki.bcs.rochester.edu/HlpLab/Projects) can be found in our lab wiki, and our publication page contains [presentations and papers about previous projects]({{site.baseurl}}/publications/). In case you're interested in our work, but do not have a background in psycholinguistics, here are some handbook references that may get you started:

  * For an introduction to language production:
    * Bock, K. and Levelt, W. (1994). Language production. In Gernsbacher, M. A., editor, Handbook of Psycholinguistics, chapter 29, pages 945–984. Academic Press, ﬁrst edition.
    * Ferreira, V. and Slevc, L. (2007). Grammatical encoding. The Oxford Handbook of Psycholinguistics, chapter 27, pages 453–469. Oxford University Press.
    * Griffin, Z. M. and Ferreira, V. S. (2006). Properties of spoken language production. In Traxler, M. and Gernsbacher, M. A., editors, Handbook of Psycholinguistics, chapter 2, pages 21–59. Academic Press, second edition.
  * For an introduction to sentence comprehension:
    * Pickering, M. J. and van Gompel, R. P. G. (2006). Syntactic parsing. In Traxler, M. and Gernsbacher, M. A., editors, Handbook of Psycholinguistics, chapter 12, pages 455–504. Academic Press, second edition.
  * A brief overview of research on processing complexity in comprehension and production
    * Jaeger, T.F. and Tily, H. (2010). [On Language ‘Utility’: Processing Complexity and Communicative Efficiency](http://www.bcs.rochester.edu/people/fjaeger/papers/JaegerTily10.pdf). WIRE: Cognitive Science.
  * For a very quick introduction to probability theory and information theory as relevant to language research:
    * Jurafsky, D. and Martin, J. H. (2008). Speech and Language Processing. Prentice Hall, second edition.
    * Manning, C. D. and Schuetze, H. (1999). Foundations of Statistical Natural Language Processing, chapter 3. Mathematical Foundations, pages 39–80. MIT Press, ﬁrst edition.
